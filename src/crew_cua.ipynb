{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to sys.path: c:\\Users\\Kirsingh\\OneDrive - Advanced Micro Devices Inc\\Desktop\\ScreenWhisper\\util\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up to project root, then into util\n",
    "util_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'util'))\n",
    "print(\"Adding to sys.path:\", util_path)\n",
    "\n",
    "if util_path not in sys.path:\n",
    "    sys.path.append(util_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from crewai import Agent, Crew, Task, LLM, Process\n",
    "import os\n",
    "import pyautogui\n",
    "from crewai.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from crew_tools import click_at, scroll, type_text_at, wait\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import importlib\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Goes up one level from current directory\n",
    "sys.path.append(parent_dir)\n",
    "from util.utils import get_som_labeled_img, check_ocr_box, get_caption_model_processor, get_yolo_model\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model_path=r\"C:\\Users\\Kirsingh\\OneDrive - Advanced Micro Devices Inc\\Desktop\\ScreenWhisper\\weights\\icon_detect\\model_v1_5.pt\"\n",
    "som_model = get_yolo_model(model_path)\n",
    "#som_model.to(device)\n",
    "print('model to {}'.format(device))\n",
    "\n",
    "\n",
    "caption_model_processor = get_caption_model_processor(model_name=\"florence2\", model_name_or_path=r\"C:\\Users\\Kirsingh\\OneDrive - Advanced Micro Devices Inc\\Desktop\\ScreenWhisper\\weights\\icon_caption_florence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(5)\n",
    "image = pyautogui.screenshot(\"screen.jpg\")\n",
    "image_path = \"screen.jpg\"\n",
    "image = Image.open(image_path)\n",
    "image_rgb = image.convert('RGB')\n",
    "print('image size:', image.size)\n",
    "\n",
    "box_overlay_ratio = max(image.size) / 3200\n",
    "draw_bbox_config = {\n",
    "    'text_scale': 0.8 * box_overlay_ratio,\n",
    "    'text_thickness': max(int(2 * box_overlay_ratio), 1),\n",
    "    'text_padding': max(int(3 * box_overlay_ratio), 1),\n",
    "    'thickness': max(int(3 * box_overlay_ratio), 1),\n",
    "}\n",
    "BOX_TRESHOLD = 0.1\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "ocr_bbox_rslt, is_goal_filtered = check_ocr_box(image_path, display_img = False, output_bb_format='xyxy', goal_filtering=None, easyocr_args={'paragraph': False, 'text_threshold':0.9}, use_paddleocr=True)\n",
    "text, ocr_bbox = ocr_bbox_rslt\n",
    "cur_time_ocr = time.time() \n",
    "\n",
    "dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(image_path, som_model, BOX_TRESHOLD = BOX_TRESHOLD, output_coord_in_ratio=True, ocr_bbox=ocr_bbox,draw_bbox_config=draw_bbox_config, caption_model_processor=caption_model_processor, ocr_text=text,use_local_semantics=True, iou_threshold=0.7, scale_img=False, batch_size=128)\n",
    "cur_time_caption = time.time() \n",
    "\n",
    "screen_width = 1920\n",
    "screen_height = 1200\n",
    "\n",
    "print(parsed_content_list)\n",
    "print(\"-------------------------------------------\")\n",
    "center_coords_and_content_str = \"\\n\".join(\n",
    "    f\"Content: {item['content']} | type: {item['type']} | Center: ({int((item['bbox'][0] + item['bbox'][2]) / 2 * screen_width)}, {int((item['bbox'][1] + item['bbox'][3]) / 2 * screen_height)})\"\n",
    "    for item in parsed_content_list\n",
    ")\n",
    "print(center_coords_and_content_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def take_screenshot():\n",
    "    '''\n",
    "    Useful to tell the screen information\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Output:\n",
    "        Returns whats on the screen\n",
    "    '''\n",
    "\n",
    "\n",
    "    image = pyautogui.screenshot(\"screen.jpg\")\n",
    "    image_path = \"screen.jpg\"\n",
    "    image = Image.open(image_path)\n",
    "    image_rgb = image.convert('RGB')\n",
    "    print('image size:', image.size)\n",
    "\n",
    "    box_overlay_ratio = max(image.size) / 3200\n",
    "    draw_bbox_config = {\n",
    "        'text_scale': 0.8 * box_overlay_ratio,\n",
    "        'text_thickness': max(int(2 * box_overlay_ratio), 1),\n",
    "        'text_padding': max(int(3 * box_overlay_ratio), 1),\n",
    "        'thickness': max(int(3 * box_overlay_ratio), 1),\n",
    "    }\n",
    "    BOX_TRESHOLD = 0.05\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    ocr_bbox_rslt, is_goal_filtered = check_ocr_box(image_path, display_img = False, output_bb_format='xyxy', goal_filtering=None, easyocr_args={'paragraph': False, 'text_threshold':0.9}, use_paddleocr=True)\n",
    "    text, ocr_bbox = ocr_bbox_rslt\n",
    "    cur_time_ocr = time.time() \n",
    "\n",
    "    dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(image_path, som_model, BOX_TRESHOLD = BOX_TRESHOLD, output_coord_in_ratio=True, ocr_bbox=ocr_bbox,draw_bbox_config=draw_bbox_config, caption_model_processor=caption_model_processor, ocr_text=text,use_local_semantics=True, iou_threshold=0.7, scale_img=False, batch_size=128)\n",
    "    cur_time_caption = time.time() \n",
    "\n",
    "    screen_width = 1920\n",
    "    screen_height = 1200\n",
    "\n",
    "    center_coords_and_content_str = \"\\n\".join(\n",
    "    f\"Content: {item['content']} | type: {item['type']} | Center: ({int((item['bbox'][0] + item['bbox'][2]) / 2 * screen_width)}, {int((item['bbox'][1] + item['bbox'][3]) / 2 * screen_height)})\"\n",
    "    for item in parsed_content_list\n",
    "    )\n",
    "    print(center_coords_and_content_str)\n",
    "\n",
    "    return f\"The current screen contains these elements Content is the name of the element, type of element and coordinates to click the element {center_coords_and_content_str}\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[click_at, type_text_at, wait, take_screenshot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_llm = LLM(\n",
    "    model=\"groq/qwen-qwq-32b\",\n",
    "    temperature=0\n",
    "    #api_key = \"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.9\n",
    "    #api_key = \"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM value is already an LLM object\n"
     ]
    }
   ],
   "source": [
    "step_reasoner = Agent(\n",
    "    role = \"Computer Use Agent\",\n",
    "    goal = \"Your goal is to execute the user query by using the tools given and the screen state given query is - {query}\",\n",
    "    backstory = '''You are an expert in automating windows using user prompts. Having great experience in\n",
    "    handling complex tasks and successfully executing the tasks.''',\n",
    "    llm = my_llm,\n",
    "    allow_delegation=False,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = Task(\n",
    "    description=('''Your task is to automate the user given query very carefully and handling every edge cases too\n",
    "    and after performing a tool call you have to take the screenshot of the screen to check and the screen\n",
    "    will tell you about the icons not whether a window is opened or not but it provides accurate coordinates\n",
    "    to click so after the action it can be said that the action is performed and based that  \n",
    "    screen output reason and take next steps andyou will not assume any coordinates to click and if you \n",
    "    are not able to get the coordinates stop and '''),\n",
    "    agent=step_reasoner,\n",
    "    expected_output = \"The output should include the steps you followed to achieve the task\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:29:37,595] [ WARNING] __init__.py:537 - Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents=[step_reasoner],\n",
    "    tasks = [task1],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mComputer Use Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mYour task is to automate the user given query very carefully and handling every edge cases too\n",
      "    and after performing a tool call you have to take the screenshot of the screen to check and the screen\n",
      "    will tell you about the icons not whether a window is opened or not but it provides accurate coordinates\n",
      "    to click so after the action it can be said that the action is performed and based that  \n",
      "    screen output reason and take next steps andyou will not assume any coordinates to click and if you \n",
      "    are not able to get the coordinates stop and \u001b[00m\n",
      "image size: (1920, 1200)\n",
      "\n",
      "0: 800x1280 23 icons, 2367.4ms\n",
      "Speed: 17.1ms preprocess, 2367.4ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 1280)\n",
      "len(filtered_boxes): 27 10\n",
      "time to get parsed content: 80.2219889163971\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mComputer Use Agent\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mOkay, I understand my task. I need to open Google Chrome, search for \"virat kohli\", and then provide the steps I took. I will use the available tools to accomplish this, taking screenshots to guide my actions and ensure accuracy. I will start by taking a screenshot to identify the Google Chrome icon.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mtake_screenshot\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "The current screen contains these elements Content is the name of the element, type of element and coordinates to click the element Content: Recycle BinKirpal_Singh | type: text | Center: (113, 97)\n",
      "Content: dataset.zipe | type: text | Center: (57, 868)\n",
      "Content: 10:29AM | type: text | Center: (1853, 1152)\n",
      "Content: 4/27/2025 | type: text | Center: (1851, 1177)\n",
      "Content: .pdf  | type: icon | Center: (166, 70)\n",
      "Content: kirpal  | type: icon | Center: (949, 215)\n",
      "Content: kirpal singh.docx  | type: icon | Center: (278, 223)\n",
      "Content: omni  | type: icon | Center: (1398, 217)\n",
      "Content: omnimodels  | type: icon | Center: (1175, 368)\n",
      "Content: kirpal singh.pptx  | type: icon | Center: (164, 701)\n",
      "Content: Find | type: icon | Center: (763, 1164)\n",
      "Content: Recycle Bin | type: icon | Center: (56, 59)\n",
      "Content: Copy | type: icon | Center: (829, 1164)\n",
      "Content: the Start menu in Windows operating systems. | type: icon | Center: (696, 1163)\n",
      "Content: Microsoft Edge browser. | type: icon | Center: (961, 1163)\n",
      "Content: folder | type: icon | Center: (894, 1164)\n",
      "Content: Mail | type: icon | Center: (1223, 1167)\n",
      "Content: System | type: icon | Center: (1029, 1163)\n",
      "Content: Google Chrome web browser | type: icon | Center: (1158, 1166)\n",
      "Content: Microsoft Office. | type: icon | Center: (1093, 1164)\n",
      "Content: Navigation Bar | type: icon | Center: (1651, 1163)\n",
      "Content: Go to previous month | type: icon | Center: (1602, 1163)\n",
      "Content: Refresh or reload the page | type: icon | Center: (1770, 1164)\n",
      "Content: Wi-Fi connectivity | type: icon | Center: (1697, 1163)\n",
      "Content: ScreenWhi | type: icon | Center: (1847, 76)\n",
      "Content: Start from previous | type: icon | Center: (1732, 1162)\n",
      "Content: Searching or magnifying glass. | type: icon | Center: (1911, 64)\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mComputer Use Agent\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mclick_at\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"x\\\": 1158, \\\"y\\\": 1166}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Successfully clicked on the 1158 and 1166 coordinates\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mComputer Use Agent\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mtake_screenshot\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "The current screen contains these elements Content is the name of the element, type of element and coordinates to click the element Content: Recycle BinKirpal_Singh | type: text | Center: (113, 97)\n",
      "Content: dataset.zipe | type: text | Center: (57, 868)\n",
      "Content: 10:29AM | type: text | Center: (1853, 1152)\n",
      "Content: 4/27/2025 | type: text | Center: (1851, 1177)\n",
      "Content: .pdf  | type: icon | Center: (166, 70)\n",
      "Content: kirpal  | type: icon | Center: (949, 215)\n",
      "Content: kirpal singh.docx  | type: icon | Center: (278, 223)\n",
      "Content: omni  | type: icon | Center: (1398, 217)\n",
      "Content: omnimodels  | type: icon | Center: (1175, 368)\n",
      "Content: kirpal singh.pptx  | type: icon | Center: (164, 701)\n",
      "Content: Find | type: icon | Center: (763, 1164)\n",
      "Content: Recycle Bin | type: icon | Center: (56, 59)\n",
      "Content: Copy | type: icon | Center: (829, 1164)\n",
      "Content: the Start menu in Windows operating systems. | type: icon | Center: (696, 1163)\n",
      "Content: Microsoft Edge browser. | type: icon | Center: (961, 1163)\n",
      "Content: folder | type: icon | Center: (894, 1164)\n",
      "Content: Mail | type: icon | Center: (1223, 1167)\n",
      "Content: System | type: icon | Center: (1029, 1163)\n",
      "Content: Google Chrome web browser | type: icon | Center: (1158, 1166)\n",
      "Content: Microsoft Office. | type: icon | Center: (1093, 1164)\n",
      "Content: Navigation Bar | type: icon | Center: (1651, 1163)\n",
      "Content: Go to previous month | type: icon | Center: (1602, 1163)\n",
      "Content: Refresh or reload the page | type: icon | Center: (1770, 1164)\n",
      "Content: Wi-Fi connectivity | type: icon | Center: (1697, 1163)\n",
      "Content: ScreenWhi | type: icon | Center: (1847, 76)\n",
      "Content: Start from previous | type: icon | Center: (1732, 1162)\n",
      "Content: Searching or magnifying glass. | type: icon | Center: (1911, 64)\n",
      "\n",
      "\n",
      "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
      "\n",
      "Tool Name: click_at\n",
      "Tool Arguments: {'x': {'description': None, 'type': 'int'}, 'y': {'description': None, 'type': 'int'}}\n",
      "Tool Description: \n",
      "    Useful to click an element on screen\n",
      "\n",
      "    Args:\n",
      "        x (int): the x coordinate of the element\n",
      "        y (int): the y coordinate of the element\n",
      "\n",
      "    Output:\n",
      "        String indicating whether the action was completed or not\n",
      "    \n",
      "Tool Name: type_text_at\n",
      "Tool Arguments: {'text': {'description': None, 'type': 'str'}, 'x': {'description': None, 'type': 'int'}, 'y': {'description': None, 'type': 'int'}}\n",
      "Tool Description: \n",
      "    Useful to write text on screen at certain coordinates\n",
      "\n",
      "    Args:\n",
      "        text(string) : the text that need to be typed\n",
      "        x(int) : center x coordinate of element\n",
      "        y(int) : center y coordinate of element\n",
      "\n",
      "    Output:\n",
      "        String indicating whether the action was completed or not\n",
      "    \n",
      "Tool Name: wait\n",
      "Tool Arguments: {}\n",
      "Tool Description: \n",
      "    Useful to wait\n",
      "\n",
      "    Args:\n",
      "        None\n",
      "\n",
      "    Output:\n",
      "        String indicating whether the action was completed or not\n",
      "    \n",
      "Tool Name: take_screenshot\n",
      "Tool Arguments: {}\n",
      "Tool Description: \n",
      "    Useful to tell the screen information\n",
      "\n",
      "    Args:\n",
      "        None\n",
      "\n",
      "    Output:\n",
      "        Returns whats on the screen\n",
      "    \n",
      "\n",
      "IMPORTANT: Use the following format in your response:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, only one name of [click_at, type_text_at, wait, take_screenshot], just the name, exactly as it's written.\n",
      "Action Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "Once all necessary information is gathered, return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "```\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:32:36,318] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"model\": \"gemini-2.0-flash\",\n",
      "              \"location\": \"global\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"24s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:32:42,773] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"18s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:32:44,547] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"16s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:25,149] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"35s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:27,613] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"33s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:29,094] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"model\": \"gemini-2.0-flash\",\n",
      "              \"location\": \"global\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"31s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:30,307] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"30s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:32,776] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"model\": \"gemini-2.0-flash\",\n",
      "              \"location\": \"global\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"28s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:35,223] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"25s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:37,740] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"23s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:33:40,155] [   ERROR] llm.py:277 - LiteLLM call failed: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"20s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopen google chrome and search for virat kohli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\crew.py:551\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    548\u001b[0m metrics: List[UsageMetrics] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[1;32m--> 551\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[0;32m    553\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\crew.py:658\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[0;32m    657\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\crew.py:760\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[1;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[0;32m    757\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    759\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[1;32m--> 760\u001b[0m task_output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m task_outputs \u001b[38;5;241m=\u001b[39m [task_output]\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\task.py:302\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[1;34m(self, agent, context, tools)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    297\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    298\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    299\u001b[0m     tools: Optional[List[BaseTool]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[0;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\task.py:366\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[1;34m(self, agent, context, tools)\u001b[0m\n\u001b[0;32m    362\u001b[0m tools \u001b[38;5;241m=\u001b[39m tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[1;32m--> 366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[0;32m    373\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[0;32m    374\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    375\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[0;32m    382\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\agent.py:255\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[1;34m(self, task, context, tools)\u001b[0m\n\u001b[0;32m    252\u001b[0m     task_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_trained_data(task_prompt\u001b[38;5;241m=\u001b[39mtask_prompt)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mask_for_human_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\agents\\crew_agent_executor.py:101\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_start_logs()\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 101\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input:\n\u001b[0;32m    104\u001b[0m     formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_human_feedback(formatted_answer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\agents\\crew_agent_executor.py:126\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_rpm_limit()\n\u001b[1;32m--> 126\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_llm_response(answer)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\agents\\crew_agent_executor.py:163\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_llm_response\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[0;32m    170\u001b[0m             content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived None or empty response from LLM call.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m             color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    172\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\crewai\\llm.py:219\u001b[0m, in \u001b[0;36mLLM.call\u001b[1;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[0;32m    194\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,  \u001b[38;5;66;03m# pass the tool schema\u001b[39;00m\n\u001b[0;32m    215\u001b[0m }\n\u001b[0;32m    217\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m--> 219\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlitellm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m response_message \u001b[38;5;241m=\u001b[39m cast(Choices, cast(ModelResponse, response)\u001b[38;5;241m.\u001b[39mchoices)[\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    222\u001b[0m ]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m    223\u001b[0m text_response \u001b[38;5;241m=\u001b[39m response_message\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\litellm\\utils.py:900\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    898\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    899\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    901\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\litellm\\main.py:2205\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[0;32m   2197\u001b[0m     gemini_api_key \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2198\u001b[0m         api_key\n\u001b[0;32m   2199\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m get_secret(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2200\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m get_secret(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPALM_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# older palm api key should also work\u001b[39;00m\n\u001b[0;32m   2201\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[0;32m   2202\u001b[0m     )\n\u001b[0;32m   2204\u001b[0m     new_params \u001b[38;5;241m=\u001b[39m deepcopy(optional_params)\n\u001b[1;32m-> 2205\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mvertex_chat_completion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   2206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2210\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   2212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_ai_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertex_ai\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2228\u001b[0m     vertex_ai_project \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2229\u001b[0m         optional_params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertex_project\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertex_ai_project\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   2231\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mvertex_project\n\u001b[0;32m   2232\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m get_secret(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERTEXAI_PROJECT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2233\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\litellm\\llms\\vertex_ai\\gemini\\vertex_and_google_ai_studio_gemini.py:1282\u001b[0m, in \u001b[0;36mVertexLLM.completion\u001b[1;34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     client \u001b[38;5;241m=\u001b[39m client\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:508\u001b[0m, in \u001b[0;36mHTTPHandler.post\u001b[1;34m(self, url, data, json, params, headers, stream, timeout, files, content)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, files\u001b[38;5;241m=\u001b[39mfiles, content\u001b[38;5;241m=\u001b[39mcontent  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     )\n\u001b[1;32m--> 508\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_lock:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m         stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m         ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m         http2_negotiated \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     82\u001b[0m             ssl_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m ssl_object\u001b[38;5;241m.\u001b[39mselected_alpn_protocol() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_sync\\connection.py:156\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    149\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_context\u001b[39m\u001b[38;5;124m\"\u001b[39m: ssl_context,\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver_hostname\u001b[39m\u001b[38;5;124m\"\u001b[39m: sni_hostname\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_origin\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    154\u001b[0m     }\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_tls\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 156\u001b[0m         stream \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\httpcore\\_backends\\sync.py:165\u001b[0m, in \u001b[0;36mSyncStream.start_tls\u001b[1;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 165\u001b[0m         sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1102\u001b[0m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1104\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1382\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1381\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "result = crew.kickoff(inputs={\"query\": \"open google chrome and search for virat kohli\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
